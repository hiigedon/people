# 百度关键词收录数爬取

----------

## 需求


1. 根据百度搜索，输入关键词，获得相应关键词的收录数。
2. 收集完数据后，根据指定的阈值进行数据分类（如大于收录数大于1000的保存在一个csv文件，其他保存在另一个csv文件中。）。
3. 爬虫效率（目前测试实现18w/1h），带宽影响很大。
4. 打包成exe，可执行文件。

## 实现

**接口**：http://www.baidu.com/s 

**传参**：data = {'wd': 关键词}

由于百度这个接口没有反爬设置，所有正确访问即可，通过Xpath+re获得想要的数据。


具体爬取内容如图所示：

![爬取内容](https://raw.githubusercontent.com/Joynice/image/master/QQ%E6%88%AA%E5%9B%BE20190624150813.jpg)

## 使用说明

1. 先将需要爬取的txt文件复制到“彩票关键词”目录，保证目录中只存在需要爬取的文件。
2. 再打开数据采集器，设置线程数，以及阈值。线程数建议20，根据带宽决定；阈值将数据进行划分出大于该值以及小于该值的两个文件。
3. 最后从结果文件夹中提取出爬取结果。


## TODO

1. 学习TK。
2. 异步
3. 优化保存。
